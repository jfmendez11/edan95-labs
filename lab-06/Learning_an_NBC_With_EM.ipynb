{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 6: Learning an NBC with EM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets load and split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import metrics, datasets, cluster\n",
    "import scipy.stats as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: 1257 \n",
      "Training Labels: 1257 \n",
      "Testing Data: 540 \n",
      "Testing Labels: 540 \n",
      "Check: True\n",
      "(1257, 64)\n",
      "(1257,)\n"
     ]
    }
   ],
   "source": [
    "digits = datasets.load_digits()\n",
    "digits_data = digits.data\n",
    "digits_split = int(len(digits_data)*0.7)\n",
    "x_train = digits_data[:digits_split]\n",
    "x_test = digits_data[digits_split:]\n",
    "digits_target = digits.target\n",
    "y_train = digits_target[:digits_split]\n",
    "y_test = digits_target[digits_split:]\n",
    "print('Training data:', len(x_train), '\\nTraining Labels:', len(y_train), '\\nTesting Data:', \n",
    "      len(x_test), '\\nTesting Labels:', len(y_test), '\\nCheck:', \n",
    "      len(digits_data) == len(x_train) + len(x_test))\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "x_train /= 16\n",
    "x_test /= 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EM Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize():\n",
    "    indexes = np.random.randint(len(digits_data), size=int(len(digits_data)*0.1))\n",
    "    theta = dict()\n",
    "    temp = dict()\n",
    "    for i in indexes:\n",
    "        k = digits_target[i]\n",
    "        pixels = digits_data[i]\n",
    "        if k not in temp:\n",
    "            temp[k] = list()\n",
    "        temp[k].append(pixels)\n",
    "        \n",
    "    for k in temp:\n",
    "        prior = 0.1\n",
    "        values = np.array(temp[k])\n",
    "        means = np.zeros(digits_data.shape[1])\n",
    "        var = np.zeros(digits_data.shape[1])\n",
    "        for i in range(len(values[0])):\n",
    "            means[i] = np.mean(values[:,i])\n",
    "            var[i] = np.var(values[:,i]) + epsilon\n",
    "        theta[k] = np.array([prior, means, var])\n",
    "    return theta\n",
    "\n",
    "classes = 10\n",
    "epsilon = 0.01\n",
    "theta_init = initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### E-Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def E_step(X, theta):\n",
    "    r = np.zeros((X.shape[0],classes)) \n",
    "    for i in range(len(X)):\n",
    "        prob = np.prod([st.norm.pdf(X[i], theta[k][1], np.sqrt(theta[k][2])) for k in range(classes)], axis = 1)\n",
    "        prod = [theta[k][0]*prob[k] for k in range(classes)]\n",
    "        den = np.sum(prod)\n",
    "        r[i,:] = prod/den    \n",
    "    return r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### M-Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def M_step(X, r):\n",
    "    r_k = {k:np.sum(r[:,k]) for k in range(10)}\n",
    "    theta = dict()\n",
    "    for k in r_k:\n",
    "        prior = r_k[k]/len(X)\n",
    "        means = np.sum([r[i][k]*X[i] for i in range(len(X))], axis=0)/r_k[k]\n",
    "        vars_ = np.sum([r[i][k]*(X[i]**2) for i in range(len(X))], axis=0)/r_k[k] - means**2 + epsilon\n",
    "        theta[k] = np.array([prior, means, vars_])\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Termination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = E_step(x_train, theta_init)\n",
    "m = M_step(x_train, e)\n",
    "for i in range(100):\n",
    "    e = E_step(x_train, m)\n",
    "    m = M_step(x_train, e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X,theta):\n",
    "    probs = np.zeros((len(X), classes))\n",
    "    for k in theta:\n",
    "        prior = theta[k][0]\n",
    "        mean = theta[k][1]\n",
    "        var = theta[k][2]\n",
    "        probs[:,k] = np.sum(np.log(st.norm.pdf(X, mean, var)) + np.log(prior), axis=1)\n",
    "    return np.argmax(probs,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction Over Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report EM:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       125\n",
      "           1       1.00      0.60      0.75       129\n",
      "           2       0.75      0.76      0.76       124\n",
      "           3       0.99      0.70      0.82       130\n",
      "           4       0.97      0.89      0.93       124\n",
      "           5       0.98      0.63      0.76       126\n",
      "           6       1.00      0.97      0.98       127\n",
      "           7       0.78      1.00      0.87       125\n",
      "           8       0.63      0.98      0.77       122\n",
      "           9       0.62      0.84      0.72       125\n",
      "\n",
      "    accuracy                           0.83      1257\n",
      "   macro avg       0.87      0.84      0.83      1257\n",
      "weighted avg       0.87      0.83      0.83      1257\n",
      "\n",
      "\n",
      "Confusion matrix EM:\n",
      "[[124   0   0   0   1   0   0   0   0   0]\n",
      " [  1  77  27   0   0   1   0   2  16   5]\n",
      " [  0   0  94   0   0   0   0   0  30   0]\n",
      " [  0   0   2  91   0   0   0   5  10  22]\n",
      " [  1   0   0   0 110   1   0  12   0   0]\n",
      " [  0   0   0   1   0  79   0   7   3  36]\n",
      " [  0   0   0   0   2   0 123   0   2   0]\n",
      " [  0   0   0   0   0   0   0 125   0   0]\n",
      " [  0   0   2   0   0   0   0   0 120   0]\n",
      " [  0   0   0   0   0   0   0  10  10 105]]\n",
      "\n",
      "Homogenity: 0.7699745138217459\n",
      "Completeness: 0.7838225875172801\n",
      "V-measure: 0.7768368408282114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "y_pred_train = predict(x_train,m)\n",
    "\n",
    "print(\"Classification report EM:\\n%s\\n\" % \n",
    "      (metrics.classification_report(y_train, y_pred_train)))\n",
    "print(\"Confusion matrix EM:\\n%s\" % metrics.confusion_matrix(y_train, y_pred_train))\n",
    "print()\n",
    "h_c_v = metrics.homogeneity_completeness_v_measure(y_train, y_pred_train)\n",
    "print('Homogenity:',h_c_v[0])\n",
    "print('Completeness:',h_c_v[1])\n",
    "print('V-measure:',h_c_v[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction Over Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report EM:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.87      0.91        53\n",
      "           1       1.00      0.57      0.72        53\n",
      "           2       0.92      0.85      0.88        53\n",
      "           3       1.00      0.58      0.74        53\n",
      "           4       0.92      0.86      0.89        57\n",
      "           5       0.93      0.48      0.64        56\n",
      "           6       1.00      0.93      0.96        54\n",
      "           7       0.71      0.89      0.79        54\n",
      "           8       0.52      0.90      0.66        52\n",
      "           9       0.49      0.82      0.62        55\n",
      "\n",
      "    accuracy                           0.77       540\n",
      "   macro avg       0.84      0.77      0.78       540\n",
      "weighted avg       0.85      0.77      0.78       540\n",
      "\n",
      "\n",
      "Confusion matrix EM:\n",
      "[[46  0  0  0  4  0  0  1  2  0]\n",
      " [ 0 30  2  0  0  1  0  0  9 11]\n",
      " [ 1  0 45  0  0  0  0  0  6  1]\n",
      " [ 0  0  0 31  0  0  0  2 12  8]\n",
      " [ 0  0  0  0 49  0  0  7  1  0]\n",
      " [ 0  0  0  0  0 27  0  0  3 26]\n",
      " [ 0  0  0  0  0  0 50  0  4  0]\n",
      " [ 1  0  0  0  0  0  0 48  5  0]\n",
      " [ 0  0  2  0  0  0  0  3 47  0]\n",
      " [ 0  0  0  0  0  1  0  7  2 45]]\n",
      "\n",
      "Homogenity: 0.69486041714555\n",
      "Completeness: 0.7193562351704097\n",
      "V-measure: 0.7068961786416413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "y_pred_test = predict(x_test,m)\n",
    "\n",
    "print(\"Classification report EM:\\n%s\\n\" % \n",
    "      (metrics.classification_report(y_test, y_pred_test)))\n",
    "print(\"Confusion matrix EM:\\n%s\" % metrics.confusion_matrix(y_test, y_pred_test))\n",
    "print()\n",
    "h_c_v = metrics.homogeneity_completeness_v_measure(y_test, y_pred_test)\n",
    "print('Homogenity:',h_c_v[0])\n",
    "print('Completeness:',h_c_v[1])\n",
    "print('V-measure:',h_c_v[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Repair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repair(y_true, y_pred):\n",
    "    k_map = dict()\n",
    "    for k in range(classes):\n",
    "        idxs = [i for i in range(len(y_test)) if y_pred[i]==k]\n",
    "        unique, counts = np.unique(y_true[idxs], return_counts=True)\n",
    "        k_map[k] = unique[np.argmax(counts)]\n",
    "    y_real = list()\n",
    "    for y in y_pred:\n",
    "        y_real.append(k_map[y])\n",
    "    return y_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report SKLearn K-Means:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       125\n",
      "           1       1.00      0.60      0.75       129\n",
      "           2       0.75      0.76      0.76       124\n",
      "           3       0.99      0.70      0.82       130\n",
      "           4       0.97      0.89      0.93       124\n",
      "           5       0.98      0.63      0.76       126\n",
      "           6       1.00      0.97      0.98       127\n",
      "           7       0.78      1.00      0.87       125\n",
      "           8       0.63      0.98      0.77       122\n",
      "           9       0.62      0.84      0.72       125\n",
      "\n",
      "    accuracy                           0.83      1257\n",
      "   macro avg       0.87      0.84      0.83      1257\n",
      "weighted avg       0.87      0.83      0.83      1257\n",
      "\n",
      "\n",
      "Confusion matrix SKLearn EM:\n",
      "[[124   0   0   0   1   0   0   0   0   0]\n",
      " [  1  77  27   0   0   1   0   2  16   5]\n",
      " [  0   0  94   0   0   0   0   0  30   0]\n",
      " [  0   0   2  91   0   0   0   5  10  22]\n",
      " [  1   0   0   0 110   1   0  12   0   0]\n",
      " [  0   0   0   1   0  79   0   7   3  36]\n",
      " [  0   0   0   0   2   0 123   0   2   0]\n",
      " [  0   0   0   0   0   0   0 125   0   0]\n",
      " [  0   0   2   0   0   0   0   0 120   0]\n",
      " [  0   0   0   0   0   0   0  10  10 105]]\n",
      "\n",
      "Homogenity: 0.7699745138217459\n",
      "Completeness: 0.7838225875172801\n",
      "V-measure: 0.7768368408282114\n",
      "\n",
      "Classification report SKLearn k-Means:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.87      0.91        53\n",
      "           1       1.00      0.57      0.72        53\n",
      "           2       0.92      0.85      0.88        53\n",
      "           3       1.00      0.58      0.74        53\n",
      "           4       0.92      0.86      0.89        57\n",
      "           5       0.93      0.48      0.64        56\n",
      "           6       1.00      0.93      0.96        54\n",
      "           7       0.71      0.89      0.79        54\n",
      "           8       0.52      0.90      0.66        52\n",
      "           9       0.49      0.82      0.62        55\n",
      "\n",
      "    accuracy                           0.77       540\n",
      "   macro avg       0.84      0.77      0.78       540\n",
      "weighted avg       0.85      0.77      0.78       540\n",
      "\n",
      "\n",
      "Confusion matrix SKLearn EM:\n",
      "[[46  0  0  0  4  0  0  1  2  0]\n",
      " [ 0 30  2  0  0  1  0  0  9 11]\n",
      " [ 1  0 45  0  0  0  0  0  6  1]\n",
      " [ 0  0  0 31  0  0  0  2 12  8]\n",
      " [ 0  0  0  0 49  0  0  7  1  0]\n",
      " [ 0  0  0  0  0 27  0  0  3 26]\n",
      " [ 0  0  0  0  0  0 50  0  4  0]\n",
      " [ 1  0  0  0  0  0  0 48  5  0]\n",
      " [ 0  0  2  0  0  0  0  3 47  0]\n",
      " [ 0  0  0  0  0  1  0  7  2 45]]\n",
      "\n",
      "Homogenity: 0.69486041714555\n",
      "Completeness: 0.7193562351704097\n",
      "V-measure: 0.7068961786416413\n"
     ]
    }
   ],
   "source": [
    "y_pred_repair = repair(y_train, y_pred_train)\n",
    "print(\"Classification report SKLearn K-Means:\\n%s\\n\" % \n",
    "      (metrics.classification_report(y_train, y_pred_repair)))\n",
    "print(\"Confusion matrix SKLearn EM:\\n%s\" % metrics.confusion_matrix(y_train, y_pred_repair))\n",
    "print()\n",
    "h_c_v = metrics.homogeneity_completeness_v_measure(y_train, y_pred_repair)\n",
    "print('Homogenity:',h_c_v[0])\n",
    "print('Completeness:',h_c_v[1])\n",
    "print('V-measure:',h_c_v[2])\n",
    "print()\n",
    "\n",
    "y_pred_test_repair = repair(y_test, y_pred_test)\n",
    "print(\"Classification report SKLearn k-Means:\\n%s\\n\" % \n",
    "      (metrics.classification_report(y_test, y_pred_test_repair)))\n",
    "print(\"Confusion matrix SKLearn EM:\\n%s\" % metrics.confusion_matrix(y_test, y_pred_test_repair))\n",
    "print()\n",
    "h_c_v = metrics.homogeneity_completeness_v_measure(y_test, y_pred_test_repair)\n",
    "print('Homogenity:',h_c_v[0])\n",
    "print('Completeness:',h_c_v[1])\n",
    "print('V-measure:',h_c_v[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SciKitLearn k-Means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report SKLearn K-Means:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       125\n",
      "           1       0.61      0.30      0.40       129\n",
      "           2       0.79      0.85      0.82       124\n",
      "           3       0.93      0.87      0.90       130\n",
      "           4       0.99      0.90      0.94       124\n",
      "           5       0.90      0.75      0.81       126\n",
      "           6       0.98      0.98      0.98       127\n",
      "           7       0.86      0.99      0.92       125\n",
      "           8       0.45      0.53      0.49       122\n",
      "           9       0.54      0.78      0.63       125\n",
      "\n",
      "    accuracy                           0.79      1257\n",
      "   macro avg       0.80      0.79      0.79      1257\n",
      "weighted avg       0.80      0.79      0.79      1257\n",
      "\n",
      "\n",
      "Confusion matrix SKLearn EM:\n",
      "[[125   0   0   0   0   0   0   0   0   0]\n",
      " [  0  39  26   0   0   0   1   0  63   0]\n",
      " [  0   1 105   3   0   0   0   4  10   1]\n",
      " [  0   0   0 113   0   2   0   2   0  13]\n",
      " [  0   4   0   0 111   0   0   7   2   0]\n",
      " [  0   0   0   2   1  94   1   0   0  28]\n",
      " [  1   0   0   0   0   0 124   0   2   0]\n",
      " [  0   1   0   0   0   0   0 124   0   0]\n",
      " [  0   4   2   1   0   6   1   1  65  42]\n",
      " [  0  15   0   3   0   3   0   6   1  97]]\n",
      "\n",
      "Homogenity: 0.7518850915084162\n",
      "Completeness: 0.7608890522628747\n",
      "V-measure: 0.7563602763095835\n",
      "\n",
      "Classification report SKLearn k-Means:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97        53\n",
      "           1       0.51      0.98      0.68        53\n",
      "           2       0.98      0.79      0.88        53\n",
      "           3       0.77      0.77      0.77        53\n",
      "           4       0.96      0.91      0.94        57\n",
      "           5       0.78      0.62      0.69        56\n",
      "           6       0.98      0.96      0.97        54\n",
      "           7       0.85      0.96      0.90        54\n",
      "           8       0.00      0.00      0.00        52\n",
      "           9       0.54      0.75      0.63        55\n",
      "\n",
      "    accuracy                           0.78       540\n",
      "   macro avg       0.73      0.77      0.74       540\n",
      "weighted avg       0.74      0.78      0.75       540\n",
      "\n",
      "\n",
      "Confusion matrix SKLearn EM:\n",
      "[[52  0  0  0  1  0  0  0  0  0]\n",
      " [ 0 52  0  0  0  1  0  0  0  0]\n",
      " [ 1  0 42  7  0  0  0  0  0  3]\n",
      " [ 0  5  0 41  0  3  0  3  0  1]\n",
      " [ 1  1  0  0 52  1  0  2  0  0]\n",
      " [ 0  0  0  0  1 35  1  0  0 19]\n",
      " [ 0  2  0  0  0  0 52  0  0  0]\n",
      " [ 0  2  0  0  0  0  0 52  0  0]\n",
      " [ 0 34  1  1  0  1  0  3  0 12]\n",
      " [ 0  5  0  4  0  4  0  1  0 41]]\n",
      "\n",
      "Homogenity: 0.715526636735302\n",
      "Completeness: 0.7624208330395996\n",
      "V-measure: 0.7382297755478943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "k_means = cluster.KMeans(n_clusters=10).fit(x_train)\n",
    "y_pred_kmeans = k_means.predict(x_train)\n",
    "y_pred_kmeans_real = repair(y_train, y_pred_kmeans)\n",
    "print(\"Classification report SKLearn K-Means:\\n%s\\n\" % \n",
    "      (metrics.classification_report(y_train, y_pred_kmeans_real)))\n",
    "print(\"Confusion matrix SKLearn EM:\\n%s\" % metrics.confusion_matrix(y_train, y_pred_kmeans_real))\n",
    "print()\n",
    "h_c_v = metrics.homogeneity_completeness_v_measure(y_train, y_pred_kmeans_real)\n",
    "print('Homogenity:',h_c_v[0])\n",
    "print('Completeness:',h_c_v[1])\n",
    "print('V-measure:',h_c_v[2])\n",
    "print()\n",
    "\n",
    "y_pred_kmeans_test = k_means.predict(x_test)\n",
    "y_pred_kmeans_test_real = repair(y_test, y_pred_kmeans_test)\n",
    "print(\"Classification report SKLearn k-Means:\\n%s\\n\" % \n",
    "      (metrics.classification_report(y_test, y_pred_kmeans_test_real)))\n",
    "print(\"Confusion matrix SKLearn EM:\\n%s\" % metrics.confusion_matrix(y_test, y_pred_kmeans_test_real))\n",
    "print()\n",
    "h_c_v = metrics.homogeneity_completeness_v_measure(y_test, y_pred_kmeans_test_real)\n",
    "print('Homogenity:',h_c_v[0])\n",
    "print('Completeness:',h_c_v[1])\n",
    "print('V-measure:',h_c_v[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
