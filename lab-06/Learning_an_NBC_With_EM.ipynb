{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 6: Learning an NBC with EM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets load and split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import metrics, datasets, cluster\n",
    "import scipy.stats as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: 1257 \n",
      "Training Labels: 1257 \n",
      "Testing Data: 540 \n",
      "Testing Labels: 540 \n",
      "Check: True\n",
      "(1257, 64)\n",
      "(1257,)\n"
     ]
    }
   ],
   "source": [
    "digits = datasets.load_digits()\n",
    "digits_data = digits.data\n",
    "digits_split = int(len(digits_data)*0.7)\n",
    "x_train = digits_data[:digits_split]\n",
    "x_test = digits_data[digits_split:]\n",
    "digits_target = digits.target\n",
    "y_train = digits_target[:digits_split]\n",
    "y_test = digits_target[digits_split:]\n",
    "print('Training data:', len(x_train), '\\nTraining Labels:', len(y_train), '\\nTesting Data:', \n",
    "      len(x_test), '\\nTesting Labels:', len(y_test), '\\nCheck:', \n",
    "      len(digits_data) == len(x_train) + len(x_test))\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "x_train /= 16\n",
    "x_test /= 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EM Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize():\n",
    "    indexes = np.random.randint(len(digits_data), size=int(len(digits_data)*0.1))\n",
    "    theta = dict()\n",
    "    temp = dict()\n",
    "    for i in indexes:\n",
    "        k = digits_target[i]\n",
    "        pixels = digits_data[i]\n",
    "        if k not in temp:\n",
    "            temp[k] = list()\n",
    "        temp[k].append(pixels)\n",
    "        \n",
    "    for k in temp:\n",
    "        prior = 0.1\n",
    "        values = np.array(temp[k])\n",
    "        means = np.zeros(digits_data.shape[1])\n",
    "        var = np.zeros(digits_data.shape[1])\n",
    "        for i in range(len(values[0])):\n",
    "            means[i] = np.mean(values[:,i])\n",
    "            var[i] = np.var(values[:,i]) + epsilon\n",
    "        theta[k] = np.array([prior, means, var])\n",
    "    return theta\n",
    "\n",
    "classes = 10\n",
    "epsilon = 0.01\n",
    "theta_init = initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### E-Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def E_step(X, theta):\n",
    "    r = np.zeros((X.shape[0],classes)) \n",
    "    for i in range(len(X)):\n",
    "        prob = np.prod([st.norm.pdf(X[i], theta[k][1], np.sqrt(theta[k][2])) for k in range(classes)], axis = 1)\n",
    "        prod = [theta[k][0]*prob[k] for k in range(classes)]\n",
    "        den = np.sum(prod)\n",
    "        r[i,:] = prod/den    \n",
    "    return r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### M-Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def M_step(X, r):\n",
    "    r_k = {k:np.sum(r[:,k]) for k in range(10)}\n",
    "    theta = dict()\n",
    "    for k in r_k:\n",
    "        prior = r_k[k]/len(X)\n",
    "        means = np.sum([r[i][k]*X[i] for i in range(len(X))], axis=0)/r_k[k]\n",
    "        vars_ = np.sum([r[i][k]*(X[i]**2) for i in range(len(X))], axis=0)/r_k[k] - means**2 + epsilon\n",
    "        theta[k] = np.array([prior, means, vars_])\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Termination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = E_step(x_train, theta_init)\n",
    "m = M_step(x_train, e)\n",
    "for i in range(100):\n",
    "    e = E_step(x_train, m)\n",
    "    m = M_step(x_train, e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X,theta):\n",
    "    probs = np.zeros((len(X), classes))\n",
    "    for k in theta:\n",
    "        prior = theta[k][0]\n",
    "        mean = theta[k][1]\n",
    "        var = theta[k][2]\n",
    "        probs[:,k] = np.sum(np.log(st.norm.pdf(X, mean, var)) + np.log(prior), axis=1)\n",
    "    return np.argmax(probs,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction Over Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report EM:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       125\n",
      "           1       0.25      0.39      0.30       129\n",
      "           2       0.77      0.74      0.75       124\n",
      "           3       0.97      0.75      0.85       130\n",
      "           4       0.96      0.89      0.92       124\n",
      "           5       0.99      0.67      0.80       126\n",
      "           6       1.00      0.95      0.98       127\n",
      "           7       0.83      0.98      0.90       125\n",
      "           8       0.13      0.10      0.11       122\n",
      "           9       0.62      0.74      0.67       125\n",
      "\n",
      "    accuracy                           0.72      1257\n",
      "   macro avg       0.75      0.72      0.73      1257\n",
      "weighted avg       0.75      0.72      0.73      1257\n",
      "\n",
      "\n",
      "Confusion matrix EM:\n",
      "[[123   0   0   0   1   0   0   0   0   1]\n",
      " [  1  50  26   0   1   0   0   1  50   0]\n",
      " [  0  25  92   0   0   0   0   0   7   0]\n",
      " [  0   4   2  98   0   0   0   3   0  23]\n",
      " [  1   0   0   0 110   1   0  11   1   0]\n",
      " [  0   4   0   1   0  84   0   4   0  33]\n",
      " [  0   1   0   0   2   0 121   0   3   0]\n",
      " [  0   0   0   0   0   0   0 123   2   0]\n",
      " [  0 110   0   0   0   0   0   0  12   0]\n",
      " [  0   8   0   2   0   0   0   7  16  92]]\n",
      "\n",
      "Homogenity: 0.7418473998956004\n",
      "Completeness: 0.752119198161969\n",
      "V-measure: 0.746947987047994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "y_pred_train = predict(x_train,m)\n",
    "\n",
    "print(\"Classification report EM:\\n%s\\n\" % \n",
    "      (metrics.classification_report(y_train, y_pred_train)))\n",
    "print(\"Confusion matrix EM:\\n%s\" % metrics.confusion_matrix(y_train, y_pred_train))\n",
    "print()\n",
    "h_c_v = metrics.homogeneity_completeness_v_measure(y_train, y_pred_train)\n",
    "print('Homogenity:',h_c_v[0])\n",
    "print('Completeness:',h_c_v[1])\n",
    "print('V-measure:',h_c_v[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction Over Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report EM:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.89      0.92        53\n",
      "           1       0.30      0.60      0.40        53\n",
      "           2       0.98      0.89      0.93        53\n",
      "           3       1.00      0.60      0.75        53\n",
      "           4       0.92      0.86      0.89        57\n",
      "           5       0.93      0.50      0.65        56\n",
      "           6       1.00      0.93      0.96        54\n",
      "           7       0.77      0.91      0.83        54\n",
      "           8       0.15      0.08      0.10        52\n",
      "           9       0.55      0.80      0.65        55\n",
      "\n",
      "    accuracy                           0.71       540\n",
      "   macro avg       0.76      0.71      0.71       540\n",
      "weighted avg       0.76      0.71      0.71       540\n",
      "\n",
      "\n",
      "Confusion matrix EM:\n",
      "[[47  1  0  0  4  0  0  1  0  0]\n",
      " [ 0 32  0  0  0  1  0  2 16  2]\n",
      " [ 1  4 47  0  0  0  0  0  0  1]\n",
      " [ 0 10  0 32  0  0  0  2  0  9]\n",
      " [ 0  1  0  0 49  0  0  6  1  0]\n",
      " [ 0  4  0  0  0 28  0  0  0 24]\n",
      " [ 0  3  0  0  0  0 50  0  1  0]\n",
      " [ 1  4  0  0  0  0  0 49  0  0]\n",
      " [ 0 47  1  0  0  0  0  0  4  0]\n",
      " [ 0  2  0  0  0  1  0  4  4 44]]\n",
      "\n",
      "Homogenity: 0.6949249395058729\n",
      "Completeness: 0.7230397021197053\n",
      "V-measure: 0.7087035974040284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "y_pred_test = predict(x_test,m)\n",
    "\n",
    "print(\"Classification report EM:\\n%s\\n\" % \n",
    "      (metrics.classification_report(y_test, y_pred_test)))\n",
    "print(\"Confusion matrix EM:\\n%s\" % metrics.confusion_matrix(y_test, y_pred_test))\n",
    "print()\n",
    "h_c_v = metrics.homogeneity_completeness_v_measure(y_test, y_pred_test)\n",
    "print('Homogenity:',h_c_v[0])\n",
    "print('Completeness:',h_c_v[1])\n",
    "print('V-measure:',h_c_v[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SciKitLearn k-Means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Repair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repair(y_true, y_pred):\n",
    "    k_map = dict()\n",
    "    for k in range(classes):\n",
    "        idxs = [i for i in range(len(y_test)) if y_pred[i]==k]\n",
    "        unique, counts = np.unique(y_true[idxs], return_counts=True)\n",
    "        k_map[k] = unique[np.argmax(counts)]\n",
    "    y_real = list()\n",
    "    for y in y_pred:\n",
    "        y_real.append(k_map[y])\n",
    "    return y_real"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report SKLearn K-Means:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       125\n",
      "           1       0.61      0.30      0.40       129\n",
      "           2       0.79      0.84      0.81       124\n",
      "           3       0.90      0.85      0.88       130\n",
      "           4       0.99      0.90      0.94       124\n",
      "           5       0.92      0.75      0.82       126\n",
      "           6       0.98      0.98      0.98       127\n",
      "           7       0.86      0.98      0.92       125\n",
      "           8       0.46      0.57      0.51       122\n",
      "           9       0.54      0.77      0.63       125\n",
      "\n",
      "    accuracy                           0.79      1257\n",
      "   macro avg       0.80      0.79      0.79      1257\n",
      "weighted avg       0.80      0.79      0.79      1257\n",
      "\n",
      "\n",
      "Confusion matrix SKLearn EM:\n",
      "[[125   0   0   0   0   0   0   0   0   0]\n",
      " [  0  39  26   0   0   0   1   0  63   0]\n",
      " [  0   1 104   3   0   0   0   4  11   1]\n",
      " [  0   0   0 111   0   2   0   2   0  15]\n",
      " [  0   4   0   0 111   0   0   7   2   0]\n",
      " [  0   0   0   2   1  94   1   0   0  28]\n",
      " [  1   0   0   0   0   0 124   0   2   0]\n",
      " [  0   1   0   0   0   0   0 123   1   0]\n",
      " [  0   4   2   3   0   4   1   1  69  38]\n",
      " [  0  15   0   4   0   2   0   6   2  96]]\n",
      "\n",
      "Homogenity: 0.746239809199489\n",
      "Completeness: 0.7552750971955278\n",
      "V-measure: 0.7507302685092899\n",
      "\n",
      "Classification report SKLearn k-Means:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97        53\n",
      "           1       0.50      0.98      0.66        53\n",
      "           2       0.98      0.79      0.88        53\n",
      "           3       0.80      0.77      0.79        53\n",
      "           4       0.96      0.91      0.94        57\n",
      "           5       0.82      0.64      0.72        56\n",
      "           6       0.98      0.98      0.98        54\n",
      "           7       0.85      0.94      0.89        54\n",
      "           8       0.00      0.00      0.00        52\n",
      "           9       0.55      0.76      0.64        55\n",
      "\n",
      "    accuracy                           0.78       540\n",
      "   macro avg       0.74      0.78      0.75       540\n",
      "weighted avg       0.74      0.78      0.75       540\n",
      "\n",
      "\n",
      "Confusion matrix SKLearn EM:\n",
      "[[52  0  0  0  1  0  0  0  0  0]\n",
      " [ 0 52  0  0  0  1  0  0  0  0]\n",
      " [ 1  1 42  6  0  0  0  0  0  3]\n",
      " [ 0  6  0 41  0  2  0  3  0  1]\n",
      " [ 1  2  0  0 52  0  0  2  0  0]\n",
      " [ 0  0  0  0  1 36  1  0  0 18]\n",
      " [ 0  1  0  0  0  0 53  0  0  0]\n",
      " [ 0  3  0  0  0  0  0 51  0  0]\n",
      " [ 0 34  1  1  0  1  0  3  0 12]\n",
      " [ 0  5  0  3  0  4  0  1  0 42]]\n",
      "\n",
      "Homogenity: 0.7162596522592003\n",
      "Completeness: 0.7645574982248802\n",
      "V-measure: 0.7396209418991384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "k_means = cluster.KMeans(n_clusters=10).fit(x_train)\n",
    "y_pred_kmeans = k_means.predict(x_train)\n",
    "y_pred_kmeans_real = repair(y_train, y_pred_kmeans)\n",
    "print(\"Classification report SKLearn K-Means:\\n%s\\n\" % \n",
    "      (metrics.classification_report(y_train, y_pred_kmeans_real)))\n",
    "print(\"Confusion matrix SKLearn EM:\\n%s\" % metrics.confusion_matrix(y_train, y_pred_kmeans_real))\n",
    "print()\n",
    "h_c_v = metrics.homogeneity_completeness_v_measure(y_train, y_pred_kmeans_real)\n",
    "print('Homogenity:',h_c_v[0])\n",
    "print('Completeness:',h_c_v[1])\n",
    "print('V-measure:',h_c_v[2])\n",
    "print()\n",
    "\n",
    "y_pred_kmeans_test = k_means.predict(x_test)\n",
    "y_pred_kmeans_test_real = repair(y_test, y_pred_kmeans_test)\n",
    "print(\"Classification report SKLearn k-Means:\\n%s\\n\" % \n",
    "      (metrics.classification_report(y_test, y_pred_kmeans_test_real)))\n",
    "print(\"Confusion matrix SKLearn EM:\\n%s\" % metrics.confusion_matrix(y_test, y_pred_kmeans_test_real))\n",
    "print()\n",
    "h_c_v = metrics.homogeneity_completeness_v_measure(y_test, y_pred_kmeans_test_real)\n",
    "print('Homogenity:',h_c_v[0])\n",
    "print('Completeness:',h_c_v[1])\n",
    "print('V-measure:',h_c_v[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
